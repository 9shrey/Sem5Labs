{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a043fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4bc717",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b91c0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rain</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rain</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rain</td>\n",
       "      <td>71</td>\n",
       "      <td>80</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outlook  Temperature  Humidity    Wind Decision\n",
       "0      Sunny           85        85    Weak       No\n",
       "1      Sunny           80        90  Strong       No\n",
       "2   Overcast           83        78    Weak      Yes\n",
       "3       Rain           70        96    Weak      Yes\n",
       "4       Rain           68        80    Weak      Yes\n",
       "5       Rain           65        70  Strong       No\n",
       "6   Overcast           64        65  Strong      Yes\n",
       "7      Sunny           72        95    Weak       No\n",
       "8      Sunny           69        70    Weak      Yes\n",
       "9       Rain           75        80    Weak      Yes\n",
       "10     Sunny           75        70  Strong      Yes\n",
       "11  Overcast           72        90  Strong      Yes\n",
       "12  Overcast           81        75    Weak      Yes\n",
       "13      Rain           71        80  Strong       No"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2698810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "{'Temperature': {64: 'Yes', 65: 'No', 68: 'Yes', 69: 'Yes', 70: 'Yes', 71: 'No', 72: {'Outlook': {'Overcast': 'Yes', 'Sunny': 'No'}}, 75: 'Yes', 80: 'No', 81: 'Yes', 83: 'Yes', 85: 'No'}}\n",
      "\n",
      "Classification for {'Outlook': 'Sunny', 'Temperature': 85, 'Humidity': 80, 'Wind': 'Weak'}: No\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "def entropy(target_col):\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    entropy = -sum((count / sum(counts)) * np.log2(count / sum(counts)) for count in counts)\n",
    "    return entropy\n",
    "\n",
    "def gain_ratio(data, split_attribute, target_attribute):\n",
    "    total_entropy = entropy(data[target_attribute])\n",
    "    values, counts = np.unique(data[split_attribute], return_counts=True)\n",
    "    weighted_entropy = sum((counts[i] / np.sum(counts)) * entropy(data.where(data[split_attribute] == values[i]).dropna()[target_attribute]) for i in range(len(values)))\n",
    "    split_info = -sum((counts[i] / np.sum(counts)) * np.log2(counts[i] / np.sum(counts)) for i in range(len(values)))\n",
    "    if split_info == 0:\n",
    "        return 0\n",
    "    gain = total_entropy - weighted_entropy\n",
    "    return gain / split_info\n",
    "\n",
    "def best_attribute(data, attributes, target_attribute):\n",
    "    best_gain = -1\n",
    "    best_attr = None\n",
    "    for attr in attributes:\n",
    "        gain = gain_ratio(data, attr, target_attribute)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_attr = attr\n",
    "    return best_attr\n",
    "\n",
    "def build_tree(data, attributes, target_attribute):\n",
    "    if len(np.unique(data[target_attribute])) == 1:\n",
    "        return data[target_attribute].iloc[0]\n",
    "    if len(attributes) == 0:\n",
    "        return data[target_attribute.mode()[0]]\n",
    "    best_attr = best_attribute(data, attributes, target_attribute)\n",
    "    tree = {best_attr: {}}\n",
    "    unique_values = np.unique(data[best_attr])\n",
    "    for value in unique_values:\n",
    "        subset = data.where(data[best_attr] == value).dropna()\n",
    "        remaining_attrs = [attr for attr in attributes if attr != best_attr]\n",
    "        tree[best_attr][value] = build_tree(subset, remaining_attrs, target_attribute)\n",
    "    return tree\n",
    "\n",
    "def classify(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    attribute = next(iter(tree))\n",
    "    attribute_value = sample[attribute]\n",
    "    if attribute_value in tree[attribute]:\n",
    "        return classify(tree[attribute][attribute_value], sample)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "attributes = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "target_attribute = 'Decision'\n",
    "decision_tree = build_tree(data, attributes, target_attribute)\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(decision_tree)\n",
    "\n",
    "new_sample = {'Outlook': 'Sunny', 'Temperature': 85, 'Humidity': 80, 'Wind': 'Weak'}\n",
    "classification = classify(decision_tree, new_sample)\n",
    "\n",
    "print(f\"\\nClassification for {new_sample}: {classification}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "451623e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "{'Outlook': {'<=': 'Yes', '>': {'Temperature': {'<=': {'Wind': {'<=': 'No', '>': 'Yes'}}, '>': 'No'}}}}\n",
      "Classification for {'Outlook': 'Sunny', 'Temperature': 85, 'Humidity': 80, 'Wind': 'Weak'}: Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "def gini_impurity(target_col):\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    impurity = 1 - sum((count / sum(counts)) ** 2 for count in counts)\n",
    "    return impurity\n",
    "\n",
    "def best_split(data, attributes, target_attribute):\n",
    "    best_gini = float('inf')\n",
    "    best_attr = None\n",
    "    best_split_value = None\n",
    "    \n",
    "    for attr in attributes:\n",
    "        values = np.unique(data[attr])\n",
    "        \n",
    "        for value in values:\n",
    "            left_subset = data[data[attr] <= value]\n",
    "            right_subset = data[data[attr] > value]\n",
    "            \n",
    "            if len(left_subset) == 0 or len(right_subset) == 0:\n",
    "                continue\n",
    "            \n",
    "            left_gini = gini_impurity(left_subset[target_attribute])\n",
    "            right_gini = gini_impurity(right_subset[target_attribute])\n",
    "            weighted_gini = (len(left_subset) / len(data)) * left_gini + (len(right_subset) / len(data)) * right_gini\n",
    "            \n",
    "            if weighted_gini < best_gini:\n",
    "                best_gini = weighted_gini\n",
    "                best_attr = attr\n",
    "                best_split_value = value\n",
    "                \n",
    "    return best_attr, best_split_value\n",
    "\n",
    "def build_tree(data, attributes, target_attribute, depth=0):\n",
    "    if len(np.unique(data[target_attribute])) == 1:\n",
    "        return data[target_attribute].iloc[0]\n",
    "    \n",
    "    if len(attributes) == 0 or depth == 3:\n",
    "        return data[target_attribute].mode()[0]  # Corrected this line\n",
    "\n",
    "    best_attr, best_split_value = best_split(data, attributes, target_attribute)\n",
    "    \n",
    "    if best_attr is None:\n",
    "        return data[target_attribute].mode()[0]\n",
    "    \n",
    "    tree = {best_attr: {}}\n",
    "    \n",
    "    left_subset = data[data[best_attr] <= best_split_value]\n",
    "    right_subset = data[data[best_attr] > best_split_value]\n",
    "    \n",
    "    remaining_attrs = [attr for attr in attributes if attr != best_attr]\n",
    "    \n",
    "    tree[best_attr]['<='] = build_tree(left_subset, remaining_attrs, target_attribute, depth + 1)\n",
    "    tree[best_attr]['>'] = build_tree(right_subset, remaining_attrs, target_attribute, depth + 1)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "def classify(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    \n",
    "    attribute = next(iter(tree))\n",
    "    attribute_value = sample[attribute]\n",
    "    \n",
    "    if attribute_value <= tree[attribute]['<=']:\n",
    "        return classify(tree[attribute]['<='], sample)\n",
    "    else:\n",
    "        return classify(tree[attribute]['>'], sample)\n",
    "\n",
    "attributes = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "target_attribute = 'Decision'\n",
    "decision_tree = build_tree(data, attributes, target_attribute)\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(decision_tree)\n",
    "\n",
    "new_sample = {'Outlook': 'Sunny', 'Temperature': 85, 'Humidity': 80, 'Wind': 'Weak'}\n",
    "classification = classify(decision_tree, new_sample)\n",
    "\n",
    "print(f\"Classification for {new_sample}: {classification}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f22a09be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 Decision Tree:\n",
      "{'Credit': {'Bad': {'Income': {'High': 'No', 'Low': 'No', 'Medium': 'Yes'}}, 'Good': 'Yes'}}\n",
      "C4.5 Classification for {'Income': 'Medium', 'Credit': 'Bad'}: Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create dataset\n",
    "data = pd.DataFrame({\n",
    "    'Income': ['Low', 'Low', 'Medium', 'Medium', 'High', 'High'],\n",
    "    'Credit': ['Good', 'Bad', 'Good', 'Bad', 'Good', 'Bad'],\n",
    "    'Loan Approved': ['Yes', 'No', 'Yes', 'Yes', 'Yes', 'No']\n",
    "})\n",
    "\n",
    "def entropy(target_col):\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    entropy = -sum((count / sum(counts)) * np.log2(count / sum(counts)) for count in counts)\n",
    "    return entropy\n",
    "\n",
    "def gain_ratio(data, split_attribute, target_attribute):\n",
    "    total_entropy = entropy(data[target_attribute])\n",
    "    values, counts = np.unique(data[split_attribute], return_counts=True)\n",
    "    weighted_entropy = sum((counts[i] / np.sum(counts)) * entropy(data[data[split_attribute] == values[i]][target_attribute]) for i in range(len(values)))\n",
    "    split_info = -sum((counts[i] / np.sum(counts)) * np.log2(counts[i] / np.sum(counts)) for i in range(len(values)))\n",
    "    if split_info == 0:\n",
    "        return 0\n",
    "    gain = total_entropy - weighted_entropy\n",
    "    return gain / split_info\n",
    "\n",
    "def best_attribute(data, attributes, target_attribute):\n",
    "    best_gain = -1\n",
    "    best_attr = None\n",
    "    for attr in attributes:\n",
    "        gain = gain_ratio(data, attr, target_attribute)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_attr = attr\n",
    "    return best_attr\n",
    "\n",
    "def build_tree(data, attributes, target_attribute):\n",
    "    if len(np.unique(data[target_attribute])) == 1:\n",
    "        return data[target_attribute].iloc[0]\n",
    "    if len(attributes) == 0:\n",
    "        return data[target_attribute.mode()[0]]\n",
    "    \n",
    "    best_attr = best_attribute(data, attributes, target_attribute)\n",
    "    tree = {best_attr: {}}\n",
    "    unique_values = np.unique(data[best_attr])\n",
    "    \n",
    "    for value in unique_values:\n",
    "        subset = data[data[best_attr] == value]\n",
    "        remaining_attrs = [attr for attr in attributes if attr != best_attr]\n",
    "        tree[best_attr][value] = build_tree(subset, remaining_attrs, target_attribute)\n",
    "        \n",
    "    return tree\n",
    "\n",
    "def classify(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    attribute = next(iter(tree))\n",
    "    attribute_value = sample[attribute]\n",
    "    return classify(tree[attribute][attribute_value], sample)\n",
    "\n",
    "attributes = ['Income', 'Credit']\n",
    "target_attribute = 'Loan Approved'\n",
    "decision_tree_c45 = build_tree(data, attributes, target_attribute)\n",
    "\n",
    "print(\"C4.5 Decision Tree:\")\n",
    "print(decision_tree_c45)\n",
    "\n",
    "new_sample = {'Income': 'Medium', 'Credit': 'Bad'}\n",
    "classification_c45 = classify(decision_tree_c45, new_sample)\n",
    "\n",
    "print(f\"C4.5 Classification for {new_sample}: {classification_c45}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6a3f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Decision Tree:\n",
      "{'Credit': {'<=': {'Income': {'<=': 'No', '>': 'Yes'}}, '>': 'Yes'}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Bad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCART Decision Tree:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(decision_tree_cart)\n\u001b[0;32m---> 61\u001b[0m classification_cart \u001b[38;5;241m=\u001b[39m \u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecision_tree_cart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCART Classification for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_sample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassification_cart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 58\u001b[0m, in \u001b[0;36mclassify\u001b[0;34m(tree, sample)\u001b[0m\n\u001b[1;32m     56\u001b[0m attribute \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(tree))\n\u001b[1;32m     57\u001b[0m attribute_value \u001b[38;5;241m=\u001b[39m sample[attribute]\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classify(\u001b[43mtree\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattribute_value\u001b[49m\u001b[43m]\u001b[49m, sample)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Bad'"
     ]
    }
   ],
   "source": [
    "def gini_impurity(target_col):\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    impurity = 1 - sum((count / sum(counts)) ** 2 for count in counts)\n",
    "    return impurity\n",
    "\n",
    "def best_split(data, attributes, target_attribute):\n",
    "    best_gini = float('inf')\n",
    "    best_attr = None\n",
    "    best_split_value = None\n",
    "    \n",
    "    for attr in attributes:\n",
    "        values = np.unique(data[attr])\n",
    "        \n",
    "        for value in values:\n",
    "            left_subset = data[data[attr] <= value]\n",
    "            right_subset = data[data[attr] > value]\n",
    "            \n",
    "            if len(left_subset) == 0 or len(right_subset) == 0:\n",
    "                continue\n",
    "            \n",
    "            left_gini = gini_impurity(left_subset[target_attribute])\n",
    "            right_gini = gini_impurity(right_subset[target_attribute])\n",
    "            weighted_gini = (len(left_subset) / len(data)) * left_gini + (len(right_subset) / len(data)) * right_gini\n",
    "            \n",
    "            if weighted_gini < best_gini:\n",
    "                best_gini = weighted_gini\n",
    "                best_attr = attr\n",
    "                best_split_value = value\n",
    "                \n",
    "    return best_attr, best_split_value\n",
    "\n",
    "def build_tree_cart(data, attributes, target_attribute):\n",
    "    if len(np.unique(data[target_attribute])) == 1:\n",
    "        return data[target_attribute].iloc[0]\n",
    "    \n",
    "    if len(attributes) == 0:\n",
    "        return data[target_attribute].mode()[0]\n",
    "    \n",
    "    best_attr, best_split_value = best_split(data, attributes, target_attribute)\n",
    "    \n",
    "    if best_attr is None:\n",
    "        return data[target_attribute].mode()[0]\n",
    "    \n",
    "    tree = {best_attr: {}}\n",
    "    \n",
    "    left_subset = data[data[best_attr] <= best_split_value]\n",
    "    right_subset = data[data[best_attr] > best_split_value]\n",
    "    \n",
    "    remaining_attrs = [attr for attr in attributes if attr != best_attr]\n",
    "    \n",
    "    tree[best_attr]['<='] = build_tree_cart(left_subset, remaining_attrs, target_attribute)\n",
    "    tree[best_attr]['>'] = build_tree_cart(right_subset, remaining_attrs, target_attribute)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "decision_tree_cart = build_tree_cart(data, attributes, target_attribute)\n",
    "\n",
    "print(\"CART Decision Tree:\")\n",
    "print(decision_tree_cart)\n",
    "\n",
    "classification_cart = classify(decision_tree_cart, new_sample)\n",
    "\n",
    "print(f\"CART Classification for {new_sample}: {classification_cart}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c96f0496",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Income', 'Credit'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Prepare data\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIncome\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCredit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoan Approved\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert categorical variables to numerical\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/base.py:6176\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6175\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Income', 'Credit'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Prepare data\n",
    "X = data[['Income', 'Credit']]\n",
    "y = data['Loan Approved']\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Create and train the C4.5 Decision Tree\n",
    "c45_model = DecisionTreeClassifier(criterion='entropy')\n",
    "c45_model.fit(X, y)\n",
    "\n",
    "# Predictions using C4.5\n",
    "c45_prediction = c45_model.predict(pd.get_dummies(pd.DataFrame(new_sample, index=[0]), drop_first=True))\n",
    "\n",
    "print(f\"C4.5 Prediction for {new_sample}: {c45_prediction[0]}\")\n",
    "\n",
    "# Create and train the CART Decision Tree\n",
    "cart_model = DecisionTreeClassifier(criterion='gini')\n",
    "cart_model.fit(X, y)\n",
    "\n",
    "# Predictions using CART\n",
    "cart_prediction = cart_model.predict(pd.get_dummies(pd.DataFrame(new_sample, index=[0]), drop_first=True))\n",
    "\n",
    "print(f\"CART Prediction for {new_sample}: {cart_prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d3339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
